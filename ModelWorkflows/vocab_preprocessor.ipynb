{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import app\n",
    "import Models.pytorch_joy_and_anger.joy_and_anger_utils as utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Establish our pytorch factory methods we are trying to reverse engineer from python code into java code:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "pt_tokenizer = get_tokenizer(\"basic_english\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "_patterns = [r'\\'',\n",
    "             r'\\\"',\n",
    "             r'\\.',\n",
    "             r'<br \\/>',\n",
    "             r',',\n",
    "             r'\\(',\n",
    "             r'\\)',\n",
    "             r'\\!',\n",
    "             r'\\?',\n",
    "             r'\\;',\n",
    "             r'\\:',\n",
    "             r'\\s+']\n",
    "\n",
    "_replacements = [' \\'  ',\n",
    "                 '',\n",
    "                 ' . ',\n",
    "                 ' ',\n",
    "                 ' , ',\n",
    "                 ' ( ',\n",
    "                 ' ) ',\n",
    "                 ' ! ',\n",
    "                 ' ? ',\n",
    "                 ' ',\n",
    "                 ' ',\n",
    "                 ' ']\n",
    "\n",
    "_patterns_dict = list((re.compile(p), r) for p, r in zip(_patterns, _replacements))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[(re.compile(r\"\\'\", re.UNICODE), \" '  \"),\n (re.compile(r'\\\"', re.UNICODE), ''),\n (re.compile(r'\\.', re.UNICODE), ' . '),\n (re.compile(r'<br \\/>', re.UNICODE), ' '),\n (re.compile(r',', re.UNICODE), ' , '),\n (re.compile(r'\\(', re.UNICODE), ' ( '),\n (re.compile(r'\\)', re.UNICODE), ' ) '),\n (re.compile(r'\\!', re.UNICODE), ' ! '),\n (re.compile(r'\\?', re.UNICODE), ' ? '),\n (re.compile(r'\\;', re.UNICODE), ' '),\n (re.compile(r'\\:', re.UNICODE), ' '),\n (re.compile(r'\\s+', re.UNICODE), ' ')]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_patterns_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def _basic_english_normalize(line):\n",
    "    r\"\"\"\n",
    "    Basic normalization for a line of text.\n",
    "    Normalization includes\n",
    "    - lowercasing\n",
    "    - complete some basic text normalization for En glish words as follows:\n",
    "        add spaces before and after '\\''\n",
    "        remove '\\\"',\n",
    "        add spaces before and after '.'\n",
    "        replace '<br \\/>'with single space\n",
    "        add spaces before and after ','\n",
    "        add spaces before and after '('\n",
    "        add spaces before and after ')'\n",
    "        add spaces before and after '!'\n",
    "        add spaces before and after '?'\n",
    "        replace ';' with single space\n",
    "        replace ':' with single space\n",
    "        replace multiple spaces with single space\n",
    "\n",
    "    Returns a list of tokens after splitting on whitespace.\n",
    "    \"\"\"\n",
    "\n",
    "    line = line.lower()\n",
    "    for pattern_re, replaced_str in _patterns_dict:\n",
    "        line = pattern_re.sub(replaced_str, line)\n",
    "    return line.split()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tokenizer = lambda line: _basic_english_normalize(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['hello', ',', 'world']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hello, world\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 7520 items\n",
      "{'joy': 0.0, 'anger': 1.0}\n",
      "('im grabbing a minute to post i feel greedy wrong', 1)\n"
     ]
    }
   ],
   "source": [
    "train_ds = utils.HappyClassifierDataset(\"train.txt\", probabilistic=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#Create a test method in similar syntax to java\n",
    "def test_tokenizer(pt_pipeline, deciphered_pipeline, ds):\n",
    "    accuracy = 0\n",
    "    total_count = 0\n",
    "    for i, (text, label) in enumerate(ds.train_data):\n",
    "        pt_text = pt_pipeline(text)\n",
    "        new_text = deciphered_pipeline(text)\n",
    "\n",
    "        # assert pt_text array equals new_text array\n",
    "        accuracy += (pt_text == new_text)\n",
    "        #print(pt_text, new_text)\n",
    "        total_count += 1\n",
    "        if i == 0:\n",
    "            print(new_text)\n",
    "\n",
    "        if (i + 1) % (len(ds.train_data) // 5) == 0:\n",
    "            print(f\"Iteration {i} | Accuracy: {accuracy / total_count} %.\")\n",
    "        if accuracy != total_count:\n",
    "            print(pt_text, new_text)\n",
    "            break\n",
    "    try:\n",
    "        assert(accuracy == total_count)\n",
    "    except AssertionError:\n",
    "        print(\"Not the same\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['im', 'grabbing', 'a', 'minute', 'to', 'post', 'i', 'feel', 'greedy', 'wrong']\n",
      "Iteration 1503 | Accuracy: 1.0 %.\n",
      "Iteration 3007 | Accuracy: 1.0 %.\n",
      "Iteration 4511 | Accuracy: 1.0 %.\n",
      "Iteration 6015 | Accuracy: 1.0 %.\n",
      "Iteration 7519 | Accuracy: 1.0 %.\n"
     ]
    }
   ],
   "source": [
    "test_tokenizer(pt_tokenizer, tokenizer, train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(['a', 'b', 'c'] == ['a', 'b'])\n",
    "print(['a', 'b', 'c'] == ['a', 'b', 'c'])\n",
    "print(['ab'] == ['a', 'b'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenizer looks good"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now create the vocab..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(list(map(lambda k: tokenizer(k), [txt for txt, label in train_ds.train_data])), specials=[\"<unk>\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[353, 96, 0, 171]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['great', 'day', \"we're\", 'having'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "vocab_pipeline = lambda sentence: vocab(tokenizer(sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3825, 0, 191, 0]\n"
     ]
    }
   ],
   "source": [
    "print(vocab_pipeline(\"Hello, world!\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "import collections"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# example input: normalized_sentence = ['im', 'grabbing', 'a', 'minute', 'to', 'post', 'i', 'feel', 'greedy', 'wrong'],\n",
    "# specials = [\"<unk>\"]\n",
    "def create_vocab(word_frequencies: dict[str, int], specials, min_freq = 1, special_first=True):\n",
    "    '''\n",
    "    Removes specials and puts them at the front or the beginning.\n",
    "    Filters out words that do not fill min_freq requirements.\n",
    "    :param word_frequencies: map of {word: freq}\n",
    "    :param specials: list of ['<unk>'] specials\n",
    "    :param min_freq: minimum frequency the word has to appear in our vocabulary\n",
    "    :param special_first: whether specials are most common in our vocab or not.\n",
    "    :return: dict of { word: freq }\n",
    "    '''\n",
    "    tokens = []\n",
    "\n",
    "    if special_first:\n",
    "        tokens.extend(specials)\n",
    "\n",
    "    specials_set = set(specials)\n",
    "\n",
    "    for word, freq in word_frequencies.items():\n",
    "        if freq >= min_freq and word not in specials_set:\n",
    "            tokens.append(word)\n",
    "\n",
    "    if special_first is False:\n",
    "        tokens.extend(specials)\n",
    "\n",
    "    res = {}\n",
    "    for i, token in enumerate(tokens):\n",
    "        res[token] = i\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def build_vocab_from_iterator_custom(normalized_sentences_list: list[list[str]], specials: list[str] = [\"<unk>\"]):\n",
    "    '''\n",
    "    Returns a map of {token: freq}. Depending on if we specify special first and min frequency we obtain a different result map.\n",
    "    :param normalized_sentences_list: List of sentences that have been tokenized. For example, [['this', ',' 'sentence'], ['hello',',','world']]\n",
    "    :param specials: list of specials\n",
    "    :return: map of { token : freq }\n",
    "    '''\n",
    "    word_frequencies = {}\n",
    "    for sentence in normalized_sentences_list:\n",
    "        for word in sentence:\n",
    "            word_frequencies[word] = word_frequencies.get(word, 0) + 1\n",
    "\n",
    "    # sort by descending frequencies then lexicographically.\n",
    "    word_frequencies = dict(sorted(word_frequencies.items(), key=lambda x: (-1 * x[1], x[0])))\n",
    "\n",
    "    return create_vocab(word_frequencies, specials)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "{'<unk>': 0,\n 'i': 1,\n 'feel': 2,\n 'and': 3,\n 'to': 4,\n 'the': 5,\n 'a': 6,\n 'that': 7,\n 'of': 8,\n 'feeling': 9,\n 'my': 10,\n 'in': 11,\n 'it': 12,\n 'like': 13,\n 'im': 14,\n 'so': 15,\n 'is': 16,\n 'have': 17,\n 'for': 18,\n 'me': 19,\n 'with': 20,\n 'this': 21,\n 'but': 22,\n 'am': 23,\n 'was': 24,\n 'be': 25,\n 'not': 26,\n 'as': 27,\n 'about': 28,\n 'on': 29,\n 'you': 30,\n 'at': 31,\n 'more': 32,\n 'just': 33,\n 'when': 34,\n 'or': 35,\n 'all': 36,\n 'because': 37,\n 'do': 38,\n 'can': 39,\n 'are': 40,\n 'very': 41,\n 'really': 42,\n 'up': 43,\n 'time': 44,\n 't': 45,\n 'out': 46,\n 'if': 47,\n 'been': 48,\n 'get': 49,\n 'what': 50,\n 'now': 51,\n 'they': 52,\n 'know': 53,\n 'myself': 54,\n 'how': 55,\n 'will': 56,\n 'by': 57,\n 'from': 58,\n 'had': 59,\n 'some': 60,\n 'them': 61,\n 'being': 62,\n 'people': 63,\n 'want': 64,\n 'little': 65,\n 'would': 66,\n 'her': 67,\n 'an': 68,\n 'make': 69,\n 'think': 70,\n 'its': 71,\n 'he': 72,\n 'one': 73,\n 'even': 74,\n 'there': 75,\n 'who': 76,\n 'something': 77,\n 'him': 78,\n 'we': 79,\n 'life': 80,\n 'going': 81,\n 'ive': 82,\n 's': 83,\n 'love': 84,\n 'much': 85,\n 'could': 86,\n 'good': 87,\n 'than': 88,\n 'still': 89,\n 'way': 90,\n 'things': 91,\n 'm': 92,\n 'dont': 93,\n 'pretty': 94,\n 'their': 95,\n 'day': 96,\n 'she': 97,\n 'too': 98,\n 'has': 99,\n 'need': 100,\n 'no': 101,\n 'back': 102,\n 'into': 103,\n 'don': 104,\n 'these': 105,\n 'go': 106,\n 'well': 107,\n 'your': 108,\n 'see': 109,\n 'also': 110,\n 'happy': 111,\n 'his': 112,\n 'bit': 113,\n 'right': 114,\n 'which': 115,\n 'other': 116,\n 'were': 117,\n 'today': 118,\n 'should': 119,\n 'over': 120,\n 'say': 121,\n 'only': 122,\n 'did': 123,\n 'always': 124,\n 'work': 125,\n 'made': 126,\n 'around': 127,\n 'our': 128,\n 'feels': 129,\n 'most': 130,\n 'then': 131,\n 'got': 132,\n 'feelings': 133,\n 'sure': 134,\n 'again': 135,\n 'enough': 136,\n 'after': 137,\n 'cant': 138,\n 'here': 139,\n 'through': 140,\n 'though': 141,\n 'help': 142,\n 'makes': 143,\n 'off': 144,\n 'every': 145,\n 'any': 146,\n 'quite': 147,\n 'where': 148,\n 'better': 149,\n 'never': 150,\n 'doing': 151,\n 'look': 152,\n 'didnt': 153,\n 'less': 154,\n 'someone': 155,\n 'such': 156,\n 'before': 157,\n 'away': 158,\n 'days': 159,\n 'down': 160,\n 'first': 161,\n 'those': 162,\n 'felt': 163,\n 'getting': 164,\n 'person': 165,\n 'anything': 166,\n 'everything': 167,\n 'few': 168,\n 'ever': 169,\n 'own': 170,\n 'having': 171,\n 'take': 172,\n 'come': 173,\n 'year': 174,\n 'find': 175,\n 'important': 176,\n 'able': 177,\n 'lot': 178,\n 'many': 179,\n 'home': 180,\n 'actually': 181,\n 'angry': 182,\n 'excited': 183,\n 'last': 184,\n 'read': 185,\n 'http': 186,\n 'friends': 187,\n 'left': 188,\n 'may': 189,\n 'said': 190,\n 'world': 191,\n 'new': 192,\n 'thought': 193,\n 'while': 194,\n 'free': 195,\n 'without': 196,\n 'glad': 197,\n 'kind': 198,\n 'part': 199,\n 'thing': 200,\n 'rather': 201,\n 'try': 202,\n 'trying': 203,\n 'thankful': 204,\n 'why': 205,\n 'cold': 206,\n 'family': 207,\n 'keep': 208,\n 'making': 209,\n 'same': 210,\n 'cool': 211,\n 'us': 212,\n 'href': 213,\n 'long': 214,\n 'others': 215,\n 'sometimes': 216,\n 'already': 217,\n 'give': 218,\n 'ok': 219,\n 'hope': 220,\n 'let': 221,\n 'safe': 222,\n 'started': 223,\n 'wonderful': 224,\n 'yet': 225,\n 'confident': 226,\n 'blog': 227,\n 'god': 228,\n 'place': 229,\n 'years': 230,\n 'comfortable': 231,\n 'ill': 232,\n 'remember': 233,\n 'special': 234,\n 'successful': 235,\n 'tell': 236,\n 'two': 237,\n 'week': 238,\n 'amazing': 239,\n 'id': 240,\n 'irritable': 241,\n 'perfect': 242,\n 'proud': 243,\n 'satisfied': 244,\n 'strong': 245,\n 'write': 246,\n 'each': 247,\n 'end': 248,\n 'might': 249,\n 'morning': 250,\n 'positive': 251,\n 'sweet': 252,\n 'blessed': 253,\n 'content': 254,\n 'didn': 255,\n 'put': 256,\n 'friend': 257,\n 'looking': 258,\n 'moment': 259,\n 'must': 260,\n 'nothing': 261,\n 'brave': 262,\n 'greedy': 263,\n 'selfish': 264,\n 'talented': 265,\n 'another': 266,\n 'cute': 267,\n 'everyone': 268,\n 'point': 269,\n 'popular': 270,\n 'rich': 271,\n 'times': 272,\n 'wanted': 273,\n 'bothered': 274,\n 'inspired': 275,\n 'night': 276,\n 'offended': 277,\n 'once': 278,\n 'school': 279,\n 'since': 280,\n 'super': 281,\n 've': 282,\n 'done': 283,\n 'fine': 284,\n 'fucked': 285,\n 'lucky': 286,\n 'next': 287,\n 'self': 288,\n 'whole': 289,\n 'annoyed': 290,\n 'convinced': 291,\n 'divine': 292,\n 'resentful': 293,\n 'accepted': 294,\n 'pleasant': 295,\n 'stop': 296,\n 'stressed': 297,\n 'useful': 298,\n 'calm': 299,\n 'creative': 300,\n 'does': 301,\n 'guess': 302,\n 'irritated': 303,\n 'old': 304,\n 'precious': 305,\n 'cranky': 306,\n 'mean': 307,\n 'share': 308,\n 'use': 309,\n 'went': 310,\n 'anyone': 311,\n 'assured': 312,\n 'honored': 313,\n 'insulted': 314,\n 'rude': 315,\n 'thinking': 316,\n 'determined': 317,\n 'frustrated': 318,\n 'hated': 319,\n 'hopeful': 320,\n 'innocent': 321,\n 'mad': 322,\n 'pissed': 323,\n 'respected': 324,\n 'start': 325,\n 'violent': 326,\n 'writing': 327,\n 'best': 328,\n 'dangerous': 329,\n 'dissatisfied': 330,\n 'hard': 331,\n 'hate': 332,\n 'mind': 333,\n 'often': 334,\n 'relaxed': 335,\n 'superior': 336,\n 'valued': 337,\n 'agitated': 338,\n 'festive': 339,\n 'friendly': 340,\n 'joyful': 341,\n 'least': 342,\n 'sincere': 343,\n 'thats': 344,\n 'truly': 345,\n 'valuable': 346,\n 'wronged': 347,\n 'bad': 348,\n 'clever': 349,\n 'face': 350,\n 'far': 351,\n 'gorgeous': 352,\n 'great': 353,\n 'jealous': 354,\n 'optimistic': 355,\n 'bitchy': 356,\n 'found': 357,\n 'generous': 358,\n 'passionate': 359,\n 'productive': 360,\n 'sleep': 361,\n 'towards': 362,\n 'become': 363,\n 'care': 364,\n 'delicious': 365,\n 'job': 366,\n 'live': 367,\n 'mellow': 368,\n 'resolved': 369,\n 'rushed': 370,\n 'smart': 371,\n 'talk': 372,\n 'wasnt': 373,\n 'distracted': 374,\n 'energetic': 375,\n 'intelligent': 376,\n 'pleased': 377,\n 'post': 378,\n 'supporting': 379,\n 'almost': 380,\n 'bitter': 381,\n 'carefree': 382,\n 'class': 383,\n 'maybe': 384,\n 'particularly': 385,\n 'past': 386,\n 'body': 387,\n 'coming': 388,\n 'leave': 389,\n 'real': 390,\n 'room': 391,\n 'welcomed': 392,\n 'especially': 393,\n 'fact': 394,\n 'petty': 395,\n 'probably': 396,\n 'rebellious': 397,\n 'disgusted': 398,\n 'eager': 399,\n 'else': 400,\n 'fabulous': 401,\n 'fantastic': 402,\n 'house': 403,\n 'kids': 404,\n 'until': 405,\n 'virtuous': 406,\n 'adventurous': 407,\n 'artistic': 408,\n 'book': 409,\n 'children': 410,\n 'lately': 411,\n 'man': 412,\n 'months': 413,\n 'peaceful': 414,\n 'relieved': 415,\n 'sense': 416,\n 'taking': 417,\n 'working': 418,\n 'worthwhile': 419,\n 'girl': 420,\n 'impatient': 421,\n 'invigorated': 422,\n 'loved': 423,\n 're': 424,\n 'reason': 425,\n 'saying': 426,\n 'show': 427,\n 'trusting': 428,\n 'ask': 429,\n 'believe': 430,\n 'big': 431,\n 'contented': 432,\n 'couldnt': 433,\n 'hear': 434,\n 'heart': 435,\n 'honoured': 436,\n 'understand': 437,\n 'extremely': 438,\n 'finally': 439,\n 'future': 440,\n 'husband': 441,\n 'longer': 442,\n 'simply': 443,\n 'smug': 444,\n 'tired': 445,\n 'told': 446,\n 'triumphant': 447,\n 'experience': 448,\n 'eyes': 449,\n 'fun': 450,\n 'pain': 451,\n 'terrific': 452,\n 'vital': 453,\n 'wish': 454,\n 'acceptable': 455,\n 'casual': 456,\n 'ecstatic': 457,\n 'grumpy': 458,\n 'inside': 459,\n 'starting': 460,\n 'stubborn': 461,\n 'thrilled': 462,\n 'used': 463,\n 'amp': 464,\n 'call': 465,\n 'change': 466,\n 'completely': 467,\n 'enjoy': 468,\n 'havent': 469,\n 'reassured': 470,\n 'run': 471,\n 'sort': 472,\n 'story': 473,\n 'support': 474,\n 'thoughts': 475,\n 'anymore': 476,\n 'cannot': 477,\n 'comes': 478,\n 'hours': 479,\n 'instead': 480,\n 'privileged': 481,\n 'reading': 482,\n 'somehow': 483,\n 'stuff': 484,\n 'walk': 485,\n 'wear': 486,\n 'alone': 487,\n 'beautiful': 488,\n 'full': 489,\n 'hurt': 490,\n 'living': 491,\n 'rest': 492,\n 'together': 493,\n 'appreciative': 494,\n 'came': 495,\n 'child': 496,\n 'energy': 497,\n 'envious': 498,\n 'head': 499,\n 'll': 500,\n 'mom': 501,\n 'shes': 502,\n 'tortured': 503,\n 'totally': 504,\n 'woman': 505,\n 'amused': 506,\n 'beloved': 507,\n 'close': 508,\n 'control': 509,\n 'decided': 510,\n 'matter': 511,\n 'seems': 512,\n 'side': 513,\n 'small': 514,\n 'food': 515,\n 'giving': 516,\n 'hes': 517,\n 'ready': 518,\n 'women': 519,\n 'absolutely': 520,\n 'bed': 521,\n 'christmas': 522,\n 'however': 523,\n 'joy': 524,\n 'needed': 525,\n 'stay': 526,\n 'stupid': 527,\n 'three': 528,\n 'woke': 529,\n 'spend': 530,\n 'youre': 531,\n 'certain': 532,\n 'definitely': 533,\n 'glamorous': 534,\n 'hair': 535,\n 'half': 536,\n 'happened': 537,\n 'hostile': 538,\n 'keen': 539,\n 'lost': 540,\n 'money': 541,\n 'move': 542,\n 'music': 543,\n 'nice': 544,\n 'sad': 545,\n 'somewhat': 546,\n 'song': 547,\n 'watch': 548,\n 'ways': 549,\n 'whatever': 550,\n 'wonder': 551,\n 'wont': 552,\n 'wrong': 553,\n 'ago': 554,\n 'asked': 555,\n 'baby': 556,\n 'course': 557,\n 'delighted': 558,\n 'different': 559,\n 'during': 560,\n 'either': 561,\n 'exactly': 562,\n 'idea': 563,\n 'knew': 564,\n 'miss': 565,\n 'ones': 566,\n 'playful': 567,\n 'sit': 568,\n 'slightly': 569,\n 'soon': 570,\n 'tonight': 571,\n 'took': 572,\n 'usually': 573,\n 'watching': 574,\n 'words': 575,\n 'against': 576,\n 'between': 577,\n 'complacent': 578,\n 'couple': 579,\n 'd': 580,\n 'doesnt': 581,\n 'faithful': 582,\n 'guys': 583,\n 'hand': 584,\n 'hateful': 585,\n 'mine': 586,\n 'needs': 587,\n 'open': 588,\n 'outside': 589,\n 'seem': 590,\n 'students': 591,\n 'wearing': 592,\n 'whether': 593,\n 'buy': 594,\n 'continue': 595,\n 'eat': 596,\n 'forward': 597,\n 'grouchy': 598,\n 'lives': 599,\n 'mother': 600,\n 'parents': 601,\n 'plan': 602,\n 'play': 603,\n 'running': 604,\n 'team': 605,\n 'theres': 606,\n 'weeks': 607,\n 'within': 608,\n 'books': 609,\n 'called': 610,\n 'gone': 611,\n 'grateful': 612,\n 'questions': 613,\n 'sitting': 614,\n 'style': 615,\n 'supposed': 616,\n 'www': 617,\n 'yesterday': 618,\n 'admit': 619,\n 'air': 620,\n 'both': 621,\n 'deal': 622,\n 'eating': 623,\n 'given': 624,\n 'happen': 625,\n 'learn': 626,\n 'listen': 627,\n 'lively': 628,\n 'mood': 629,\n 'relationship': 630,\n 'set': 631,\n 'single': 632,\n 'smile': 633,\n 'true': 634,\n 'turn': 635,\n 'worked': 636,\n 'along': 637,\n 'elegant': 638,\n 'healthy': 639,\n 'hour': 640,\n 'learning': 641,\n 'movie': 642,\n 'possibly': 643,\n 'weekend': 644,\n 'young': 645,\n 'comments': 646,\n 'entertained': 647,\n 'front': 648,\n 'heartless': 649,\n 'honestly': 650,\n 'knowing': 651,\n 'lose': 652,\n 'means': 653,\n 'met': 654,\n 'normal': 655,\n 'opportunity': 656,\n 'seeing': 657,\n 'sociable': 658,\n 'summer': 659,\n 'talking': 660,\n 'trust': 661,\n 'wanting': 662,\n 'weight': 663,\n 'whenever': 664,\n 'yes': 665,\n 'arms': 666,\n 'began': 667,\n 'behind': 668,\n 'cause': 669,\n 'doesn': 670,\n 'fall': 671,\n 'guy': 672,\n 'incredibly': 673,\n 'kinda': 674,\n 'listening': 675,\n 'moments': 676,\n 'moving': 677,\n 'piece': 678,\n 'sarcastic': 679,\n 'saw': 680,\n 'spent': 681,\n 'state': 682,\n 'under': 683,\n 'walked': 684,\n 'wasn': 685,\n 'word': 686,\n 'although': 687,\n 'art': 688,\n 'boy': 689,\n 'charming': 690,\n 'country': 691,\n 'cry': 692,\n 'etc': 693,\n 'film': 694,\n 'gets': 695,\n 'goes': 696,\n 'isnt': 697,\n 'list': 698,\n 'minutes': 699,\n 'realize': 700,\n 'stories': 701,\n 'theyre': 702,\n 'upon': 703,\n 'waiting': 704,\n 'wake': 705,\n 'warm': 706,\n 'age': 707,\n 'bouncy': 708,\n 'chance': 709,\n 'choice': 710,\n 'game': 711,\n 'girls': 712,\n 'high': 713,\n 'human': 714,\n 'kept': 715,\n 'name': 716,\n 'obnoxious': 717,\n 'order': 718,\n 'outraged': 719,\n 'problems': 720,\n 'red': 721,\n 'second': 722,\n 'situation': 723,\n 'sun': 724,\n 'type': 725,\n 'worth': 726,\n 'deeply': 727,\n 'easy': 728,\n 'effort': 729,\n 'fairly': 730,\n 'finish': 731,\n 'gave': 732,\n 'group': 733,\n 'imagine': 734,\n 'jolly': 735,\n 'later': 736,\n 'looks': 737,\n 'lots': 738,\n 'peace': 739,\n 'personal': 740,\n 'picture': 741,\n 'please': 742,\n 'realized': 743,\n 'seen': 744,\n 'speak': 745,\n 'strongly': 746,\n 'suddenly': 747,\n 'taken': 748,\n 'themselves': 749,\n 'trip': 750,\n 'truthful': 751,\n 'upset': 752,\n 'weather': 753,\n 'won': 754,\n 'allowed': 755,\n 'community': 756,\n 'damn': 757,\n 'despite': 758,\n 'dream': 759,\n 'finished': 760,\n 'fit': 761,\n 'generally': 762,\n 'knowledge': 763,\n 'lazy': 764,\n 'month': 765,\n 'number': 766,\n 'phone': 767,\n 'photos': 768,\n 'putting': 769,\n 'quickly': 770,\n 'results': 771,\n 'src': 772,\n 'stand': 773,\n 'telling': 774,\n 'top': 775,\n 'toward': 776,\n 'walking': 777,\n 'wants': 778,\n 'add': 779,\n 'answer': 780,\n 'asking': 781,\n 'break': 782,\n 'career': 783,\n 'decision': 784,\n 'deep': 785,\n 'desire': 786,\n 'door': 787,\n 'expect': 788,\n 'gift': 789,\n 'hands': 790,\n 'lack': 791,\n 'learned': 792,\n 'line': 793,\n 'lovely': 794,\n 'loving': 795,\n 'men': 796,\n 'personally': 797,\n 'reasons': 798,\n 'season': 799,\n 'sound': 800,\n 'tried': 801,\n 'u': 802,\n 'voice': 803,\n 'wait': 804,\n 'across': 805,\n 'act': 806,\n 'anger': 807,\n 'black': 808,\n 'crap': 809,\n 'create': 810,\n 'decide': 811,\n 'evening': 812,\n 'everyday': 813,\n 'extra': 814,\n 'focus': 815,\n 'furious': 816,\n 'general': 817,\n 'gracious': 818,\n 'happiness': 819,\n 'helping': 820,\n 'img': 821,\n 'issue': 822,\n 'light': 823,\n 'managed': 824,\n 'meet': 825,\n 'news': 826,\n 'oh': 827,\n 'party': 828,\n 'perhaps': 829,\n 'possible': 830,\n 'posting': 831,\n 'respect': 832,\n 'sat': 833,\n 'says': 834,\n 'series': 835,\n 'sick': 836,\n 'space': 837,\n 'wanna': 838,\n 'whats': 839,\n 'afraid': 840,\n 'ahead': 841,\n 'angered': 842,\n 'anyway': 843,\n 'b': 844,\n 'begin': 845,\n 'belong': 846,\n 'bring': 847,\n 'busy': 848,\n 'car': 849,\n 'certainly': 850,\n 'choose': 851,\n 'clothes': 852,\n 'college': 853,\n 'confidence': 854,\n 'dance': 855,\n 'depressed': 856,\n 'dinner': 857,\n 'drink': 858,\n 'due': 859,\n 'early': 860,\n 'enjoyed': 861,\n 'express': 862,\n 'fab': 863,\n 'fearless': 864,\n 'forget': 865,\n 'four': 866,\n 'goal': 867,\n 'graceful': 868,\n 'health': 869,\n 'known': 870,\n 'level': 871,\n 'lol': 872,\n 'lonely': 873,\n 'offer': 874,\n 'path': 875,\n 'presence': 876,\n 'received': 877,\n 'recently': 878,\n 'seriously': 879,\n 'several': 880,\n 'shit': 881,\n 'sister': 882,\n 'slowly': 883,\n 'son': 884,\n 'tend': 885,\n 'tomorrow': 886,\n 'usual': 887,\n 'win': 888,\n 'works': 889,\n 'accept': 890,\n 'aggravated': 891,\n 'appreciate': 892,\n 'beginning': 893,\n 'blogging': 894,\n 'brain': 895,\n 'breath': 896,\n 'characters': 897,\n 'connection': 898,\n 'dress': 899,\n 'emotions': 900,\n 'enjoying': 901,\n 'event': 902,\n 'exercise': 903,\n 'fear': 904,\n 'five': 905,\n 'further': 906,\n 'games': 907,\n 'gotten': 908,\n 'happening': 909,\n 'hold': 910,\n 'hoping': 911,\n 'hot': 912,\n 'issues': 913,\n 'itself': 914,\n 'keeping': 915,\n 'late': 916,\n 'leaving': 917,\n 'members': 918,\n 'negative': 919,\n 'nor': 920,\n 'posts': 921,\n 'problem': 922,\n 'project': 923,\n 'projects': 924,\n 'race': 925,\n 'spending': 926,\n 'spirit': 927,\n 'step': 928,\n 'stress': 929,\n 'talked': 930,\n 'thank': 931,\n 'throughout': 932,\n 'video': 933,\n 'ability': 934,\n 'artist': 935,\n 'attempt': 936,\n 'bitch': 937,\n 'business': 938,\n 'church': 939,\n 'comment': 940,\n 'computer': 941,\n 'conversation': 942,\n 'created': 943,\n 'daily': 944,\n 'ended': 945,\n 'equally': 946,\n 'eye': 947,\n 'facebook': 948,\n 'fans': 949,\n 'finding': 950,\n 'gonna': 951,\n 'hell': 952,\n 'himself': 953,\n 'holiday': 954,\n 'immediately': 955,\n 'journey': 956,\n 'lie': 957,\n 'loss': 958,\n 'onto': 959,\n 'pass': 960,\n 'playing': 961,\n 'progress': 962,\n 'push': 963,\n 'saturday': 964,\n 'shake': 965,\n 'skin': 966,\n 'somewhere': 967,\n 'songs': 968,\n 'sorry': 969,\n 'struggle': 970,\n 'success': 971,\n 'suppose': 972,\n 'tears': 973,\n 'terribly': 974,\n 'thanks': 975,\n 'throw': 976,\n 'title': 977,\n 'touch': 978,\n 'training': 979,\n 'treat': 980,\n 'truth': 981,\n 'universe': 982,\n 'whom': 983,\n 'worried': 984,\n 'written': 985,\n 'above': 986,\n 'accomplished': 987,\n 'added': 988,\n 'allow': 989,\n 'appalled': 990,\n 'attention': 991,\n 'author': 992,\n 'awesome': 993,\n 'birthday': 994,\n 'bought': 995,\n 'boyfriend': 996,\n 'changed': 997,\n 'chocolate': 998,\n 'clear': 999,\n ...}"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_vocab_from_iterator_custom(list(map(lambda k: tokenizer(k), [txt for txt, label in train_ds.train_data])), specials=[\"<unk>\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def build_vocab_from_tokenized_sentences_optimized(normalized_sentences_list: list[list[str]], specials: list[str] = [\"<unk>\"]):\n",
    "    word_frequencies = {}\n",
    "    specials_set = set(specials)\n",
    "    max_freq = -1\n",
    "    for sentence in normalized_sentences_list:\n",
    "        for word in sentence:\n",
    "            if word not in specials_set:\n",
    "                word_frequencies[word] = word_frequencies.get(word, 0) + 1\n",
    "                max_freq = max(max_freq, word_frequencies[word])\n",
    "    biggest_freq_after = max_freq + 1\n",
    "    for special in specials:\n",
    "        word_frequencies[special] = biggest_freq_after\n",
    "        biggest_freq_after += 1\n",
    "\n",
    "    word_frequencies_sorted = {k: v for k, v in sorted(word_frequencies.items(), key=lambda x: (-x[1], x[0]))}\n",
    "    res = {}\n",
    "    for i, (word, freq) in enumerate(word_frequencies_sorted.items()):\n",
    "        res[word] = i\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "{'<unk>': 0,\n 'i': 1,\n 'feel': 2,\n 'and': 3,\n 'to': 4,\n 'the': 5,\n 'a': 6,\n 'that': 7,\n 'of': 8,\n 'feeling': 9,\n 'my': 10,\n 'in': 11,\n 'it': 12,\n 'like': 13,\n 'im': 14,\n 'so': 15,\n 'is': 16,\n 'have': 17,\n 'for': 18,\n 'me': 19,\n 'with': 20,\n 'this': 21,\n 'but': 22,\n 'am': 23,\n 'was': 24,\n 'be': 25,\n 'not': 26,\n 'as': 27,\n 'about': 28,\n 'on': 29,\n 'you': 30,\n 'at': 31,\n 'more': 32,\n 'just': 33,\n 'when': 34,\n 'or': 35,\n 'all': 36,\n 'because': 37,\n 'do': 38,\n 'can': 39,\n 'are': 40,\n 'very': 41,\n 'really': 42,\n 'up': 43,\n 'time': 44,\n 't': 45,\n 'out': 46,\n 'if': 47,\n 'been': 48,\n 'get': 49,\n 'what': 50,\n 'now': 51,\n 'they': 52,\n 'know': 53,\n 'myself': 54,\n 'how': 55,\n 'will': 56,\n 'by': 57,\n 'from': 58,\n 'had': 59,\n 'some': 60,\n 'them': 61,\n 'being': 62,\n 'people': 63,\n 'want': 64,\n 'little': 65,\n 'would': 66,\n 'her': 67,\n 'an': 68,\n 'make': 69,\n 'think': 70,\n 'its': 71,\n 'he': 72,\n 'one': 73,\n 'even': 74,\n 'there': 75,\n 'who': 76,\n 'something': 77,\n 'him': 78,\n 'we': 79,\n 'life': 80,\n 'going': 81,\n 'ive': 82,\n 's': 83,\n 'love': 84,\n 'much': 85,\n 'could': 86,\n 'good': 87,\n 'than': 88,\n 'still': 89,\n 'way': 90,\n 'things': 91,\n 'm': 92,\n 'dont': 93,\n 'pretty': 94,\n 'their': 95,\n 'day': 96,\n 'she': 97,\n 'too': 98,\n 'has': 99,\n 'need': 100,\n 'no': 101,\n 'back': 102,\n 'into': 103,\n 'don': 104,\n 'these': 105,\n 'go': 106,\n 'well': 107,\n 'your': 108,\n 'see': 109,\n 'also': 110,\n 'happy': 111,\n 'his': 112,\n 'bit': 113,\n 'right': 114,\n 'which': 115,\n 'other': 116,\n 'were': 117,\n 'today': 118,\n 'should': 119,\n 'over': 120,\n 'say': 121,\n 'only': 122,\n 'did': 123,\n 'always': 124,\n 'work': 125,\n 'made': 126,\n 'around': 127,\n 'our': 128,\n 'feels': 129,\n 'most': 130,\n 'then': 131,\n 'got': 132,\n 'feelings': 133,\n 'sure': 134,\n 'again': 135,\n 'enough': 136,\n 'after': 137,\n 'cant': 138,\n 'here': 139,\n 'through': 140,\n 'though': 141,\n 'help': 142,\n 'makes': 143,\n 'off': 144,\n 'every': 145,\n 'any': 146,\n 'quite': 147,\n 'where': 148,\n 'better': 149,\n 'never': 150,\n 'doing': 151,\n 'look': 152,\n 'didnt': 153,\n 'less': 154,\n 'someone': 155,\n 'such': 156,\n 'before': 157,\n 'away': 158,\n 'days': 159,\n 'down': 160,\n 'first': 161,\n 'those': 162,\n 'felt': 163,\n 'getting': 164,\n 'person': 165,\n 'anything': 166,\n 'everything': 167,\n 'few': 168,\n 'ever': 169,\n 'own': 170,\n 'having': 171,\n 'take': 172,\n 'come': 173,\n 'year': 174,\n 'find': 175,\n 'important': 176,\n 'able': 177,\n 'lot': 178,\n 'many': 179,\n 'home': 180,\n 'actually': 181,\n 'angry': 182,\n 'excited': 183,\n 'last': 184,\n 'read': 185,\n 'http': 186,\n 'friends': 187,\n 'left': 188,\n 'may': 189,\n 'said': 190,\n 'world': 191,\n 'new': 192,\n 'thought': 193,\n 'while': 194,\n 'free': 195,\n 'without': 196,\n 'glad': 197,\n 'kind': 198,\n 'part': 199,\n 'thing': 200,\n 'rather': 201,\n 'try': 202,\n 'trying': 203,\n 'thankful': 204,\n 'why': 205,\n 'cold': 206,\n 'family': 207,\n 'keep': 208,\n 'making': 209,\n 'same': 210,\n 'cool': 211,\n 'us': 212,\n 'href': 213,\n 'long': 214,\n 'others': 215,\n 'sometimes': 216,\n 'already': 217,\n 'give': 218,\n 'ok': 219,\n 'hope': 220,\n 'let': 221,\n 'safe': 222,\n 'started': 223,\n 'wonderful': 224,\n 'yet': 225,\n 'confident': 226,\n 'blog': 227,\n 'god': 228,\n 'place': 229,\n 'years': 230,\n 'comfortable': 231,\n 'ill': 232,\n 'remember': 233,\n 'special': 234,\n 'successful': 235,\n 'tell': 236,\n 'two': 237,\n 'week': 238,\n 'amazing': 239,\n 'id': 240,\n 'irritable': 241,\n 'perfect': 242,\n 'proud': 243,\n 'satisfied': 244,\n 'strong': 245,\n 'write': 246,\n 'each': 247,\n 'end': 248,\n 'might': 249,\n 'morning': 250,\n 'positive': 251,\n 'sweet': 252,\n 'blessed': 253,\n 'content': 254,\n 'didn': 255,\n 'put': 256,\n 'friend': 257,\n 'looking': 258,\n 'moment': 259,\n 'must': 260,\n 'nothing': 261,\n 'brave': 262,\n 'greedy': 263,\n 'selfish': 264,\n 'talented': 265,\n 'another': 266,\n 'cute': 267,\n 'everyone': 268,\n 'point': 269,\n 'popular': 270,\n 'rich': 271,\n 'times': 272,\n 'wanted': 273,\n 'bothered': 274,\n 'inspired': 275,\n 'night': 276,\n 'offended': 277,\n 'once': 278,\n 'school': 279,\n 'since': 280,\n 'super': 281,\n 've': 282,\n 'done': 283,\n 'fine': 284,\n 'fucked': 285,\n 'lucky': 286,\n 'next': 287,\n 'self': 288,\n 'whole': 289,\n 'annoyed': 290,\n 'convinced': 291,\n 'divine': 292,\n 'resentful': 293,\n 'accepted': 294,\n 'pleasant': 295,\n 'stop': 296,\n 'stressed': 297,\n 'useful': 298,\n 'calm': 299,\n 'creative': 300,\n 'does': 301,\n 'guess': 302,\n 'irritated': 303,\n 'old': 304,\n 'precious': 305,\n 'cranky': 306,\n 'mean': 307,\n 'share': 308,\n 'use': 309,\n 'went': 310,\n 'anyone': 311,\n 'assured': 312,\n 'honored': 313,\n 'insulted': 314,\n 'rude': 315,\n 'thinking': 316,\n 'determined': 317,\n 'frustrated': 318,\n 'hated': 319,\n 'hopeful': 320,\n 'innocent': 321,\n 'mad': 322,\n 'pissed': 323,\n 'respected': 324,\n 'start': 325,\n 'violent': 326,\n 'writing': 327,\n 'best': 328,\n 'dangerous': 329,\n 'dissatisfied': 330,\n 'hard': 331,\n 'hate': 332,\n 'mind': 333,\n 'often': 334,\n 'relaxed': 335,\n 'superior': 336,\n 'valued': 337,\n 'agitated': 338,\n 'festive': 339,\n 'friendly': 340,\n 'joyful': 341,\n 'least': 342,\n 'sincere': 343,\n 'thats': 344,\n 'truly': 345,\n 'valuable': 346,\n 'wronged': 347,\n 'bad': 348,\n 'clever': 349,\n 'face': 350,\n 'far': 351,\n 'gorgeous': 352,\n 'great': 353,\n 'jealous': 354,\n 'optimistic': 355,\n 'bitchy': 356,\n 'found': 357,\n 'generous': 358,\n 'passionate': 359,\n 'productive': 360,\n 'sleep': 361,\n 'towards': 362,\n 'become': 363,\n 'care': 364,\n 'delicious': 365,\n 'job': 366,\n 'live': 367,\n 'mellow': 368,\n 'resolved': 369,\n 'rushed': 370,\n 'smart': 371,\n 'talk': 372,\n 'wasnt': 373,\n 'distracted': 374,\n 'energetic': 375,\n 'intelligent': 376,\n 'pleased': 377,\n 'post': 378,\n 'supporting': 379,\n 'almost': 380,\n 'bitter': 381,\n 'carefree': 382,\n 'class': 383,\n 'maybe': 384,\n 'particularly': 385,\n 'past': 386,\n 'body': 387,\n 'coming': 388,\n 'leave': 389,\n 'real': 390,\n 'room': 391,\n 'welcomed': 392,\n 'especially': 393,\n 'fact': 394,\n 'petty': 395,\n 'probably': 396,\n 'rebellious': 397,\n 'disgusted': 398,\n 'eager': 399,\n 'else': 400,\n 'fabulous': 401,\n 'fantastic': 402,\n 'house': 403,\n 'kids': 404,\n 'until': 405,\n 'virtuous': 406,\n 'adventurous': 407,\n 'artistic': 408,\n 'book': 409,\n 'children': 410,\n 'lately': 411,\n 'man': 412,\n 'months': 413,\n 'peaceful': 414,\n 'relieved': 415,\n 'sense': 416,\n 'taking': 417,\n 'working': 418,\n 'worthwhile': 419,\n 'girl': 420,\n 'impatient': 421,\n 'invigorated': 422,\n 'loved': 423,\n 're': 424,\n 'reason': 425,\n 'saying': 426,\n 'show': 427,\n 'trusting': 428,\n 'ask': 429,\n 'believe': 430,\n 'big': 431,\n 'contented': 432,\n 'couldnt': 433,\n 'hear': 434,\n 'heart': 435,\n 'honoured': 436,\n 'understand': 437,\n 'extremely': 438,\n 'finally': 439,\n 'future': 440,\n 'husband': 441,\n 'longer': 442,\n 'simply': 443,\n 'smug': 444,\n 'tired': 445,\n 'told': 446,\n 'triumphant': 447,\n 'experience': 448,\n 'eyes': 449,\n 'fun': 450,\n 'pain': 451,\n 'terrific': 452,\n 'vital': 453,\n 'wish': 454,\n 'acceptable': 455,\n 'casual': 456,\n 'ecstatic': 457,\n 'grumpy': 458,\n 'inside': 459,\n 'starting': 460,\n 'stubborn': 461,\n 'thrilled': 462,\n 'used': 463,\n 'amp': 464,\n 'call': 465,\n 'change': 466,\n 'completely': 467,\n 'enjoy': 468,\n 'havent': 469,\n 'reassured': 470,\n 'run': 471,\n 'sort': 472,\n 'story': 473,\n 'support': 474,\n 'thoughts': 475,\n 'anymore': 476,\n 'cannot': 477,\n 'comes': 478,\n 'hours': 479,\n 'instead': 480,\n 'privileged': 481,\n 'reading': 482,\n 'somehow': 483,\n 'stuff': 484,\n 'walk': 485,\n 'wear': 486,\n 'alone': 487,\n 'beautiful': 488,\n 'full': 489,\n 'hurt': 490,\n 'living': 491,\n 'rest': 492,\n 'together': 493,\n 'appreciative': 494,\n 'came': 495,\n 'child': 496,\n 'energy': 497,\n 'envious': 498,\n 'head': 499,\n 'll': 500,\n 'mom': 501,\n 'shes': 502,\n 'tortured': 503,\n 'totally': 504,\n 'woman': 505,\n 'amused': 506,\n 'beloved': 507,\n 'close': 508,\n 'control': 509,\n 'decided': 510,\n 'matter': 511,\n 'seems': 512,\n 'side': 513,\n 'small': 514,\n 'food': 515,\n 'giving': 516,\n 'hes': 517,\n 'ready': 518,\n 'women': 519,\n 'absolutely': 520,\n 'bed': 521,\n 'christmas': 522,\n 'however': 523,\n 'joy': 524,\n 'needed': 525,\n 'stay': 526,\n 'stupid': 527,\n 'three': 528,\n 'woke': 529,\n 'spend': 530,\n 'youre': 531,\n 'certain': 532,\n 'definitely': 533,\n 'glamorous': 534,\n 'hair': 535,\n 'half': 536,\n 'happened': 537,\n 'hostile': 538,\n 'keen': 539,\n 'lost': 540,\n 'money': 541,\n 'move': 542,\n 'music': 543,\n 'nice': 544,\n 'sad': 545,\n 'somewhat': 546,\n 'song': 547,\n 'watch': 548,\n 'ways': 549,\n 'whatever': 550,\n 'wonder': 551,\n 'wont': 552,\n 'wrong': 553,\n 'ago': 554,\n 'asked': 555,\n 'baby': 556,\n 'course': 557,\n 'delighted': 558,\n 'different': 559,\n 'during': 560,\n 'either': 561,\n 'exactly': 562,\n 'idea': 563,\n 'knew': 564,\n 'miss': 565,\n 'ones': 566,\n 'playful': 567,\n 'sit': 568,\n 'slightly': 569,\n 'soon': 570,\n 'tonight': 571,\n 'took': 572,\n 'usually': 573,\n 'watching': 574,\n 'words': 575,\n 'against': 576,\n 'between': 577,\n 'complacent': 578,\n 'couple': 579,\n 'd': 580,\n 'doesnt': 581,\n 'faithful': 582,\n 'guys': 583,\n 'hand': 584,\n 'hateful': 585,\n 'mine': 586,\n 'needs': 587,\n 'open': 588,\n 'outside': 589,\n 'seem': 590,\n 'students': 591,\n 'wearing': 592,\n 'whether': 593,\n 'buy': 594,\n 'continue': 595,\n 'eat': 596,\n 'forward': 597,\n 'grouchy': 598,\n 'lives': 599,\n 'mother': 600,\n 'parents': 601,\n 'plan': 602,\n 'play': 603,\n 'running': 604,\n 'team': 605,\n 'theres': 606,\n 'weeks': 607,\n 'within': 608,\n 'books': 609,\n 'called': 610,\n 'gone': 611,\n 'grateful': 612,\n 'questions': 613,\n 'sitting': 614,\n 'style': 615,\n 'supposed': 616,\n 'www': 617,\n 'yesterday': 618,\n 'admit': 619,\n 'air': 620,\n 'both': 621,\n 'deal': 622,\n 'eating': 623,\n 'given': 624,\n 'happen': 625,\n 'learn': 626,\n 'listen': 627,\n 'lively': 628,\n 'mood': 629,\n 'relationship': 630,\n 'set': 631,\n 'single': 632,\n 'smile': 633,\n 'true': 634,\n 'turn': 635,\n 'worked': 636,\n 'along': 637,\n 'elegant': 638,\n 'healthy': 639,\n 'hour': 640,\n 'learning': 641,\n 'movie': 642,\n 'possibly': 643,\n 'weekend': 644,\n 'young': 645,\n 'comments': 646,\n 'entertained': 647,\n 'front': 648,\n 'heartless': 649,\n 'honestly': 650,\n 'knowing': 651,\n 'lose': 652,\n 'means': 653,\n 'met': 654,\n 'normal': 655,\n 'opportunity': 656,\n 'seeing': 657,\n 'sociable': 658,\n 'summer': 659,\n 'talking': 660,\n 'trust': 661,\n 'wanting': 662,\n 'weight': 663,\n 'whenever': 664,\n 'yes': 665,\n 'arms': 666,\n 'began': 667,\n 'behind': 668,\n 'cause': 669,\n 'doesn': 670,\n 'fall': 671,\n 'guy': 672,\n 'incredibly': 673,\n 'kinda': 674,\n 'listening': 675,\n 'moments': 676,\n 'moving': 677,\n 'piece': 678,\n 'sarcastic': 679,\n 'saw': 680,\n 'spent': 681,\n 'state': 682,\n 'under': 683,\n 'walked': 684,\n 'wasn': 685,\n 'word': 686,\n 'although': 687,\n 'art': 688,\n 'boy': 689,\n 'charming': 690,\n 'country': 691,\n 'cry': 692,\n 'etc': 693,\n 'film': 694,\n 'gets': 695,\n 'goes': 696,\n 'isnt': 697,\n 'list': 698,\n 'minutes': 699,\n 'realize': 700,\n 'stories': 701,\n 'theyre': 702,\n 'upon': 703,\n 'waiting': 704,\n 'wake': 705,\n 'warm': 706,\n 'age': 707,\n 'bouncy': 708,\n 'chance': 709,\n 'choice': 710,\n 'game': 711,\n 'girls': 712,\n 'high': 713,\n 'human': 714,\n 'kept': 715,\n 'name': 716,\n 'obnoxious': 717,\n 'order': 718,\n 'outraged': 719,\n 'problems': 720,\n 'red': 721,\n 'second': 722,\n 'situation': 723,\n 'sun': 724,\n 'type': 725,\n 'worth': 726,\n 'deeply': 727,\n 'easy': 728,\n 'effort': 729,\n 'fairly': 730,\n 'finish': 731,\n 'gave': 732,\n 'group': 733,\n 'imagine': 734,\n 'jolly': 735,\n 'later': 736,\n 'looks': 737,\n 'lots': 738,\n 'peace': 739,\n 'personal': 740,\n 'picture': 741,\n 'please': 742,\n 'realized': 743,\n 'seen': 744,\n 'speak': 745,\n 'strongly': 746,\n 'suddenly': 747,\n 'taken': 748,\n 'themselves': 749,\n 'trip': 750,\n 'truthful': 751,\n 'upset': 752,\n 'weather': 753,\n 'won': 754,\n 'allowed': 755,\n 'community': 756,\n 'damn': 757,\n 'despite': 758,\n 'dream': 759,\n 'finished': 760,\n 'fit': 761,\n 'generally': 762,\n 'knowledge': 763,\n 'lazy': 764,\n 'month': 765,\n 'number': 766,\n 'phone': 767,\n 'photos': 768,\n 'putting': 769,\n 'quickly': 770,\n 'results': 771,\n 'src': 772,\n 'stand': 773,\n 'telling': 774,\n 'top': 775,\n 'toward': 776,\n 'walking': 777,\n 'wants': 778,\n 'add': 779,\n 'answer': 780,\n 'asking': 781,\n 'break': 782,\n 'career': 783,\n 'decision': 784,\n 'deep': 785,\n 'desire': 786,\n 'door': 787,\n 'expect': 788,\n 'gift': 789,\n 'hands': 790,\n 'lack': 791,\n 'learned': 792,\n 'line': 793,\n 'lovely': 794,\n 'loving': 795,\n 'men': 796,\n 'personally': 797,\n 'reasons': 798,\n 'season': 799,\n 'sound': 800,\n 'tried': 801,\n 'u': 802,\n 'voice': 803,\n 'wait': 804,\n 'across': 805,\n 'act': 806,\n 'anger': 807,\n 'black': 808,\n 'crap': 809,\n 'create': 810,\n 'decide': 811,\n 'evening': 812,\n 'everyday': 813,\n 'extra': 814,\n 'focus': 815,\n 'furious': 816,\n 'general': 817,\n 'gracious': 818,\n 'happiness': 819,\n 'helping': 820,\n 'img': 821,\n 'issue': 822,\n 'light': 823,\n 'managed': 824,\n 'meet': 825,\n 'news': 826,\n 'oh': 827,\n 'party': 828,\n 'perhaps': 829,\n 'possible': 830,\n 'posting': 831,\n 'respect': 832,\n 'sat': 833,\n 'says': 834,\n 'series': 835,\n 'sick': 836,\n 'space': 837,\n 'wanna': 838,\n 'whats': 839,\n 'afraid': 840,\n 'ahead': 841,\n 'angered': 842,\n 'anyway': 843,\n 'b': 844,\n 'begin': 845,\n 'belong': 846,\n 'bring': 847,\n 'busy': 848,\n 'car': 849,\n 'certainly': 850,\n 'choose': 851,\n 'clothes': 852,\n 'college': 853,\n 'confidence': 854,\n 'dance': 855,\n 'depressed': 856,\n 'dinner': 857,\n 'drink': 858,\n 'due': 859,\n 'early': 860,\n 'enjoyed': 861,\n 'express': 862,\n 'fab': 863,\n 'fearless': 864,\n 'forget': 865,\n 'four': 866,\n 'goal': 867,\n 'graceful': 868,\n 'health': 869,\n 'known': 870,\n 'level': 871,\n 'lol': 872,\n 'lonely': 873,\n 'offer': 874,\n 'path': 875,\n 'presence': 876,\n 'received': 877,\n 'recently': 878,\n 'seriously': 879,\n 'several': 880,\n 'shit': 881,\n 'sister': 882,\n 'slowly': 883,\n 'son': 884,\n 'tend': 885,\n 'tomorrow': 886,\n 'usual': 887,\n 'win': 888,\n 'works': 889,\n 'accept': 890,\n 'aggravated': 891,\n 'appreciate': 892,\n 'beginning': 893,\n 'blogging': 894,\n 'brain': 895,\n 'breath': 896,\n 'characters': 897,\n 'connection': 898,\n 'dress': 899,\n 'emotions': 900,\n 'enjoying': 901,\n 'event': 902,\n 'exercise': 903,\n 'fear': 904,\n 'five': 905,\n 'further': 906,\n 'games': 907,\n 'gotten': 908,\n 'happening': 909,\n 'hold': 910,\n 'hoping': 911,\n 'hot': 912,\n 'issues': 913,\n 'itself': 914,\n 'keeping': 915,\n 'late': 916,\n 'leaving': 917,\n 'members': 918,\n 'negative': 919,\n 'nor': 920,\n 'posts': 921,\n 'problem': 922,\n 'project': 923,\n 'projects': 924,\n 'race': 925,\n 'spending': 926,\n 'spirit': 927,\n 'step': 928,\n 'stress': 929,\n 'talked': 930,\n 'thank': 931,\n 'throughout': 932,\n 'video': 933,\n 'ability': 934,\n 'artist': 935,\n 'attempt': 936,\n 'bitch': 937,\n 'business': 938,\n 'church': 939,\n 'comment': 940,\n 'computer': 941,\n 'conversation': 942,\n 'created': 943,\n 'daily': 944,\n 'ended': 945,\n 'equally': 946,\n 'eye': 947,\n 'facebook': 948,\n 'fans': 949,\n 'finding': 950,\n 'gonna': 951,\n 'hell': 952,\n 'himself': 953,\n 'holiday': 954,\n 'immediately': 955,\n 'journey': 956,\n 'lie': 957,\n 'loss': 958,\n 'onto': 959,\n 'pass': 960,\n 'playing': 961,\n 'progress': 962,\n 'push': 963,\n 'saturday': 964,\n 'shake': 965,\n 'skin': 966,\n 'somewhere': 967,\n 'songs': 968,\n 'sorry': 969,\n 'struggle': 970,\n 'success': 971,\n 'suppose': 972,\n 'tears': 973,\n 'terribly': 974,\n 'thanks': 975,\n 'throw': 976,\n 'title': 977,\n 'touch': 978,\n 'training': 979,\n 'treat': 980,\n 'truth': 981,\n 'universe': 982,\n 'whom': 983,\n 'worried': 984,\n 'written': 985,\n 'above': 986,\n 'accomplished': 987,\n 'added': 988,\n 'allow': 989,\n 'appalled': 990,\n 'attention': 991,\n 'author': 992,\n 'awesome': 993,\n 'birthday': 994,\n 'bought': 995,\n 'boyfriend': 996,\n 'changed': 997,\n 'chocolate': 998,\n 'clear': 999,\n ...}"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_vocab_from_tokenized_sentences_optimized(list(map(lambda k: tokenizer(k), [txt for txt, label in train_ds.train_data])), specials=[\"<unk>\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Created our functions, let's compare them all, some repetition here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "[353, 96, 0, 171]"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "vocab_from_factory = build_vocab_from_iterator(list(map(lambda k: tokenizer(k), [txt for txt, label in train_ds.train_data])),\n",
    "                                  specials=[\"<unk>\"])\n",
    "vocab_from_factory.set_default_index(vocab[\"<unk>\"])\n",
    "vocab_from_factory(['great', 'day', \"we're\", 'having'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "vocab_from_custom_detailed = build_vocab_from_iterator_custom(list(map(lambda k: tokenizer(k), [txt for txt, label in train_ds.train_data])))\n",
    "def vocab_from_custom_lambda(vocab_map, tokenized):\n",
    "    res = []\n",
    "    for token in tokenized:\n",
    "        res.append(vocab_map.get(token, 0))\n",
    "    return res\n",
    "vocab_from_custom_detailed_pipeline = lambda sentence: vocab_from_custom_lambda(vocab_from_custom_detailed, tokenizer(sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "[3825, 0, 191, 0]"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_from_custom_detailed_pipeline(\"Hello, world!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "vocab_from_custom_optimized = build_vocab_from_tokenized_sentences_optimized(list(map(lambda k: _basic_english_normalize(k), [txt for txt, label in train_ds.train_data])))\n",
    "vocab_from_custom_optimized_pipeline = lambda sentence: vocab_from_custom_lambda(vocab_from_custom_optimized, tokenizer(sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "[3825, 0, 191, 0]"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_from_custom_optimized_pipeline(\"Hello, world!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "#Create a test method in similar syntax to java\n",
    "def test_vocab(pt_pipeline, deciphered_pipeline, ds):\n",
    "    accuracy = 0\n",
    "    total_count = 0\n",
    "    for i, (text, label) in enumerate(ds.train_data):\n",
    "        pt_text = pt_pipeline(text)\n",
    "        new_text = deciphered_pipeline(text)\n",
    "\n",
    "        # assert pt_text array equals new_text array\n",
    "        accuracy += (pt_text == new_text)\n",
    "        #print(pt_text, new_text)\n",
    "        total_count += 1\n",
    "        if i == 0:\n",
    "            print(new_text)\n",
    "\n",
    "        if (i + 1) % (len(ds.train_data) // 5) == 0:\n",
    "            print(f\"Iteration {i} | Accuracy: {accuracy / total_count} %.\")\n",
    "        if accuracy != total_count:\n",
    "            print(pt_text, new_text)\n",
    "            break\n",
    "    try:\n",
    "        assert(accuracy == total_count)\n",
    "    except AssertionError:\n",
    "        print(\"Not the same\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 6945, 6, 1033, 4, 378, 1, 2, 263, 553]\n",
      "Iteration 1503 | Accuracy: 1.0 %.\n",
      "Iteration 3007 | Accuracy: 1.0 %.\n",
      "Iteration 4511 | Accuracy: 1.0 %.\n",
      "Iteration 6015 | Accuracy: 1.0 %.\n",
      "Iteration 7519 | Accuracy: 1.0 %.\n"
     ]
    }
   ],
   "source": [
    "test_vocab(vocab_from_custom_optimized_pipeline, vocab_from_custom_detailed_pipeline, train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 6945, 6, 1033, 4, 378, 1, 2, 263, 553]\n",
      "Iteration 1503 | Accuracy: 1.0 %.\n",
      "Iteration 3007 | Accuracy: 1.0 %.\n",
      "Iteration 4511 | Accuracy: 1.0 %.\n",
      "Iteration 6015 | Accuracy: 1.0 %.\n",
      "Iteration 7519 | Accuracy: 1.0 %.\n"
     ]
    }
   ],
   "source": [
    "test_vocab(vocab_pipeline, vocab_from_custom_optimized_pipeline, train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}