{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import Models.pytorch_joy_and_anger.joy_and_anger_utils as model_utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 7520 items\n",
      "{'joy': 0.0, 'anger': 1.0}\n",
      "('im grabbing a minute to post i feel greedy wrong', 1)\n",
      "loaded 970 items\n",
      "{'joy': 0.0, 'anger': 1.0}\n",
      "('i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived', 0)\n"
     ]
    }
   ],
   "source": [
    "train_ds = model_utils.HappyClassifierDataset(\"train.txt\", probabilistic=True)\n",
    "test_ds = model_utils.HappyClassifierDataset(\"test.txt\", probabilistic=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(list(map(lambda k: tokenizer(k), [txt for txt, label in train_ds.train_data])), specials=[\"<unk>\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[353, 96, 0, 171]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['great', 'day', \"we're\", 'having'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# idx 2 has issues"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    text_list, label_list, offsets = [], [], [0]\n",
    "    for text, label in batch:\n",
    "        processed_text = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        label_list.append(label_pipeline(label))\n",
    "        offsets.append(processed_text.size(0))\n",
    "    text_list = torch.cat(text_list)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    return text_list.to(device), label_list.to(device), offsets.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PyTorch seems to have a LSTM layer (mostly) similar to tf2 so we don't have to create it from scratch here."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "#TODO: Build a Backward RNN forward pass\n",
    "class HappyClassifierModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes):\n",
    "        super(HappyClassifierModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=64, bidirectional=False)\n",
    "        self.linear1 = nn.Linear(64, 32)\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            self.linear1,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear2 = nn.Linear(32, 2)\n",
    "        self.fc2 = nn.Sequential(\n",
    "            self.linear2\n",
    "        )\n",
    "\n",
    "        # self.fc = nn.Sequential(\n",
    "        #     self.linear1,\n",
    "        #     nn.ReLU(),\n",
    "        #     self.linear2\n",
    "        # )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.35\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        # how to reset bias?\n",
    "        for lstm_weight in self.lstm.all_weights:\n",
    "            for lstm_weight_inner in lstm_weight:\n",
    "                lstm_weight_inner.data.uniform_(-initrange, initrange)\n",
    "        self.linear1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear1.bias.data.zero_()\n",
    "        self.linear2.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        layer = self.embedding(text, offsets)\n",
    "        # use output of lstm\n",
    "        layer = self.lstm(layer)[0]\n",
    "        layer = self.fc1(layer)\n",
    "        layer = self.fc2(layer)\n",
    "        return layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "num_class = 2\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = HappyClassifierModel(vocab_size, emsize, num_class).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=64, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([  14, 6945,    6,  ...,  119,    2,   94]),\n tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n         0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n         0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n tensor([   0,   10,   14,   33,   54,   66,  108,  118,  130,  139,  166,  184,\n          205,  214,  226,  260,  305,  317,  326,  351,  380,  407,  430,  457,\n          484,  502,  566,  572,  580,  592,  597,  630,  660,  679,  702,  741,\n          753,  769,  794,  832,  845,  862,  867,  889,  912,  921,  933,  959,\n          981,  997, 1014, 1031, 1048, 1063, 1104, 1113, 1133, 1156, 1177, 1221,\n         1257, 1266, 1296, 1301]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verify our data can go through the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "tensor(1)\n",
      "tensor([  14, 6945,    6,  ...,  119,    2,   94]) tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([   0,   10,   14,   33,   54,   66,  108,  118,  130,  139,  166,  184,\n",
      "         205,  214,  226,  260,  305,  317,  326,  351,  380,  407,  430,  457,\n",
      "         484,  502,  566,  572,  580,  592,  597,  630,  660,  679,  702,  741,\n",
      "         753,  769,  794,  832,  845,  862,  867,  889,  912,  921,  933,  959,\n",
      "         981,  997, 1014, 1031, 1048, 1063, 1104, 1113, 1133, 1156, 1177, 1221,\n",
      "        1257, 1266, 1296, 1301])\n",
      "tensor([[ 0.0581, -0.0582],\n",
      "        [ 0.1046, -0.0590],\n",
      "        [ 0.1500, -0.0767],\n",
      "        [ 0.1139, -0.0579],\n",
      "        [ 0.0898, -0.0433],\n",
      "        [ 0.1235, -0.0582],\n",
      "        [ 0.1435, -0.0873],\n",
      "        [ 0.0792, -0.0307],\n",
      "        [ 0.1286, -0.0716],\n",
      "        [ 0.1353, -0.0590],\n",
      "        [ 0.1458, -0.0874],\n",
      "        [ 0.1300, -0.0891],\n",
      "        [ 0.0788, -0.0798],\n",
      "        [ 0.1271, -0.1219],\n",
      "        [ 0.1448, -0.0982],\n",
      "        [ 0.1482, -0.1108],\n",
      "        [ 0.0893, -0.1007],\n",
      "        [ 0.1069, -0.1671],\n",
      "        [ 0.1076, -0.1128],\n",
      "        [ 0.1120, -0.1525],\n",
      "        [ 0.1052, -0.1745],\n",
      "        [ 0.1393, -0.1119],\n",
      "        [ 0.1313, -0.0801],\n",
      "        [ 0.1182, -0.0985],\n",
      "        [ 0.0999, -0.1066],\n",
      "        [ 0.1534, -0.0917],\n",
      "        [ 0.1544, -0.1038],\n",
      "        [ 0.0922, -0.1569],\n",
      "        [ 0.0896, -0.1164],\n",
      "        [ 0.0331, -0.0396],\n",
      "        [ 0.0898, -0.0516],\n",
      "        [ 0.1222, -0.0741],\n",
      "        [ 0.1056, -0.0657],\n",
      "        [ 0.1296, -0.0519],\n",
      "        [ 0.1117, -0.0657],\n",
      "        [ 0.1951, -0.1118],\n",
      "        [ 0.2198, -0.1464],\n",
      "        [ 0.2019, -0.0957],\n",
      "        [ 0.1941, -0.0738],\n",
      "        [ 0.1772, -0.0531],\n",
      "        [ 0.2153, -0.1150],\n",
      "        [ 0.1360, -0.1040],\n",
      "        [ 0.1177, -0.0980],\n",
      "        [ 0.1486, -0.1141],\n",
      "        [ 0.1857, -0.1545],\n",
      "        [ 0.1524, -0.1282],\n",
      "        [ 0.1419, -0.1123],\n",
      "        [ 0.1353, -0.1150],\n",
      "        [ 0.1475, -0.1078],\n",
      "        [ 0.1369, -0.1107],\n",
      "        [ 0.1364, -0.1176],\n",
      "        [ 0.1278, -0.0761],\n",
      "        [ 0.1243, -0.0952],\n",
      "        [ 0.1419, -0.1064],\n",
      "        [ 0.1561, -0.1029],\n",
      "        [ 0.1561, -0.1132],\n",
      "        [ 0.1677, -0.0872],\n",
      "        [ 0.1874, -0.1010],\n",
      "        [ 0.1834, -0.1062],\n",
      "        [ 0.1426, -0.0955],\n",
      "        [ 0.0704, -0.0741],\n",
      "        [ 0.1057, -0.1115],\n",
      "        [ 0.1377, -0.1845],\n",
      "        [ 0.1698, -0.1114]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i, (txt, label, offset) in enumerate(train_dataloader):\n",
    "    model.eval()\n",
    "    print(label.shape)\n",
    "    print(label[0])\n",
    "    print(txt, label, offset)\n",
    "    print(model(txt, offset))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# lets try these hyperparameters, losses, and optimizers instead and see our results\n",
    "\n",
    "epochs = 200\n",
    "LR = 2\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1.0, gamma=0.0001)\n",
    "total_accu = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# redfine our datasets\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(dataset=test_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_accuracy, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, (texts, labels, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(texts, offsets)\n",
    "        labels = torch.as_tensor([a.type(torch.LongTensor) for a in labels], dtype=torch.int64)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        #our result is the largest number's index of the prediction\n",
    "        total_accuracy += (pred.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "\n",
    "        if i == 0:\n",
    "            print(loss)\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, i, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (texts, labels, offsets) in enumerate(dataloader):\n",
    "            pred = model(texts, offsets)\n",
    "            labels = torch.as_tensor([a.type(torch.LongTensor) for a in labels], dtype=torch.int64)\n",
    "            loss = criterion(pred, labels)\n",
    "            total_acc += (pred.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "            # print(pred)\n",
    "    return total_acc/total_count\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6419, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  2.11s | valid accuracy    0.716 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.6083, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.68s | valid accuracy    0.716 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.6589, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.88s | valid accuracy    0.716 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.6238, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  2.19s | valid accuracy    0.720 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.4974, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  2.08s | valid accuracy    0.758 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.4655, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  2.12s | valid accuracy    0.776 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.5091, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.99s | valid accuracy    0.822 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.1759, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  2.12s | valid accuracy    0.881 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.2022, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.97s | valid accuracy    0.899 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.1606, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  2.04s | valid accuracy    0.915 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(test_dataloader)\n",
    "\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)\n",
    "\n",
    "    if total_accu is not None and total_accu > 0.9:\n",
    "        # the accuracy is worse than the tf version (due to various reasons)\n",
    "        # but i dont have time\n",
    "        # so i'm removing bidirectional and just deploying a 94%\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "test out a save"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import app\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "target_path = os.path.join(app.root(), \"Models\", \"pytorch_joy_and_anger\", \"pytorch_joy_and_anger_model\")\n",
    "target_path_torchscript = os.path.join(app.root(), \"Models\", \"pytorch_joy_and_anger\", \"pytorch_joy_and_anger_model_torchscript.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "save_model(model, target_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# save as a torchscript file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   1,   23,    9,  ..., 1421,    8,   78]) tensor([   0,    6,   41,   75,   90,   96,  127,  135,  153,  172,  203,  235,\n",
      "         259,  265,  285,  302,  316,  324,  346,  353,  362,  379,  394,  411,\n",
      "         426,  435,  448,  462,  476,  491,  520,  545,  563,  582,  607,  636,\n",
      "         657,  679,  721,  738,  757,  773,  801,  818,  844,  859,  906,  946,\n",
      "         966,  980,  990,  998, 1030, 1041, 1045, 1053, 1072, 1091, 1097, 1124,\n",
      "        1139, 1156, 1167, 1192]) tensor([[-2.2134,  1.9760],\n",
      "        [ 1.9690, -1.9991],\n",
      "        [ 1.1586, -1.1731],\n",
      "        [-0.3817,  0.2516],\n",
      "        [ 1.8585, -1.8005],\n",
      "        [ 2.2694, -2.2180],\n",
      "        [-3.1842,  2.9145],\n",
      "        [ 0.7230, -0.8468],\n",
      "        [ 3.3000, -3.3359],\n",
      "        [ 1.6006, -1.6855],\n",
      "        [-3.1403,  2.7869],\n",
      "        [ 1.5438, -1.5435],\n",
      "        [ 2.1144, -2.1840],\n",
      "        [-1.8069,  1.5879],\n",
      "        [-2.3785,  2.0692],\n",
      "        [-0.8294,  0.6598],\n",
      "        [-2.6006,  2.3777],\n",
      "        [-1.8412,  1.7261],\n",
      "        [ 4.0181, -3.9622],\n",
      "        [ 0.9232, -0.9282],\n",
      "        [-2.1946,  2.0327],\n",
      "        [ 0.9085, -0.9223],\n",
      "        [-1.0980,  1.0096],\n",
      "        [ 1.4008, -1.3758],\n",
      "        [ 5.0734, -4.9929],\n",
      "        [ 1.1746, -1.2045],\n",
      "        [ 1.0186, -1.0254],\n",
      "        [ 4.3124, -4.1323],\n",
      "        [ 0.3156, -0.3604],\n",
      "        [ 0.2876, -0.2898],\n",
      "        [ 2.2101, -2.1725],\n",
      "        [ 0.0860, -0.1653],\n",
      "        [-1.5364,  1.3722],\n",
      "        [ 2.0008, -2.0438],\n",
      "        [ 0.9945, -1.0705],\n",
      "        [ 4.3873, -4.3200],\n",
      "        [-0.8162,  0.6549],\n",
      "        [ 1.2092, -1.2786],\n",
      "        [ 0.6001, -0.7380],\n",
      "        [ 0.3966, -0.5108],\n",
      "        [ 3.2147, -3.1828],\n",
      "        [-2.1600,  1.9662],\n",
      "        [-2.8482,  2.5916],\n",
      "        [ 2.6263, -2.5940],\n",
      "        [ 1.2254, -1.2458],\n",
      "        [-0.9645,  0.7855],\n",
      "        [-0.0055, -0.0927],\n",
      "        [-0.4897,  0.3895],\n",
      "        [ 2.6308, -2.5618],\n",
      "        [-2.2182,  1.9969],\n",
      "        [-1.8302,  1.6565],\n",
      "        [-0.0286, -0.1020],\n",
      "        [-2.4143,  2.1696],\n",
      "        [ 1.9225, -1.9602],\n",
      "        [ 1.3075, -1.2832],\n",
      "        [ 0.1860, -0.3060],\n",
      "        [-1.0601,  0.9042],\n",
      "        [ 4.6092, -4.4634],\n",
      "        [-0.0285, -0.1332],\n",
      "        [ 3.8440, -3.7497],\n",
      "        [ 1.0140, -1.0702],\n",
      "        [ 2.7499, -2.6963],\n",
      "        [-0.1562, -0.0088],\n",
      "        [ 2.8979, -2.8787]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "for i, (texts, labels, offsets) in enumerate(test_dataloader):\n",
    "    if i != 0:\n",
    "        break\n",
    "    traced_script_module = torch.jit.trace(model, (texts, offsets))\n",
    "    traced_script_module.save(target_path_torchscript)\n",
    "    pred = model(texts, offsets)\n",
    "    print(texts, offsets, pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3133)\n"
     ]
    }
   ],
   "source": [
    "pred = torch.as_tensor([[1., 0.]], dtype=torch.float32)\n",
    "label = torch.as_tensor([0,], dtype=torch.int64)\n",
    "\n",
    "loss = criterion(pred, label)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1269)\n"
     ]
    }
   ],
   "source": [
    "pred = torch.as_tensor([[-1., 1.]], dtype=torch.float32)\n",
    "label = torch.as_tensor([1, ], dtype=torch.int64)\n",
    "\n",
    "loss = criterion(pred, label)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loss function makes sense and matches our argmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "b = [5,6,7,8]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 3, 4, 5, 6, 7, 8])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.as_tensor(a),torch.as_tensor(b)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}