{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import Models.pytorch_joy_and_anger.joy_and_anger_utils as model_utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 7520 items\n",
      "{'joy': 0.0, 'anger': 1.0}\n",
      "('im grabbing a minute to post i feel greedy wrong', 1)\n",
      "loaded 970 items\n",
      "{'joy': 0.0, 'anger': 1.0}\n",
      "('i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived', 0)\n"
     ]
    }
   ],
   "source": [
    "train_ds = model_utils.HappyClassifierDataset(\"train.txt\", probabilistic=True)\n",
    "test_ds = model_utils.HappyClassifierDataset(\"test.txt\", probabilistic=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(list(map(lambda k: tokenizer(k), [txt for txt, label in train_ds.train_data])), specials=[\"<unk>\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[353, 96, 0, 171]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['great', 'day', \"we're\", 'having'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<function torchtext.data.utils._basic_english_normalize(line)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# idx 2 has issues"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    text_list, label_list, offsets = [], [], [0]\n",
    "    for text, label in batch:\n",
    "        processed_text = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        label_list.append(label_pipeline(label))\n",
    "        offsets.append(processed_text.size(0))\n",
    "    text_list = torch.cat(text_list)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    return text_list.to(device), label_list.to(device), offsets.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PyTorch seems to have a LSTM layer (mostly) similar to tf2 so we don't have to create it from scratch here."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "#TODO: Build a Backward RNN forward pass\n",
    "class HappyClassifierModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes):\n",
    "        super(HappyClassifierModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=64, bidirectional=False)\n",
    "        self.linear1 = nn.Linear(64, 32)\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            self.linear1,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear2 = nn.Linear(32, 2)\n",
    "        self.fc2 = nn.Sequential(\n",
    "            self.linear2\n",
    "        )\n",
    "\n",
    "        # self.fc = nn.Sequential(\n",
    "        #     self.linear1,\n",
    "        #     nn.ReLU(),\n",
    "        #     self.linear2\n",
    "        # )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.35\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        # how to reset bias?\n",
    "        for lstm_weight in self.lstm.all_weights:\n",
    "            for lstm_weight_inner in lstm_weight:\n",
    "                lstm_weight_inner.data.uniform_(-initrange, initrange)\n",
    "        self.linear1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear1.bias.data.zero_()\n",
    "        self.linear2.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        layer = self.embedding(text, offsets)\n",
    "        # use output of lstm\n",
    "        layer = self.lstm(layer)[0]\n",
    "        layer = self.fc1(layer)\n",
    "        layer = self.fc2(layer)\n",
    "        return layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "num_class = 2\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = HappyClassifierModel(vocab_size, emsize, num_class).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=64, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([  14, 6945,    6,  ...,  119,    2,   94]),\n tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n         0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n         0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n tensor([   0,   10,   14,   33,   54,   66,  108,  118,  130,  139,  166,  184,\n          205,  214,  226,  260,  305,  317,  326,  351,  380,  407,  430,  457,\n          484,  502,  566,  572,  580,  592,  597,  630,  660,  679,  702,  741,\n          753,  769,  794,  832,  845,  862,  867,  889,  912,  921,  933,  959,\n          981,  997, 1014, 1031, 1048, 1063, 1104, 1113, 1133, 1156, 1177, 1221,\n         1257, 1266, 1296, 1301]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verify our data can go through the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "tensor(1)\n",
      "tensor([  14, 6945,    6,  ...,  119,    2,   94]) tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([   0,   10,   14,   33,   54,   66,  108,  118,  130,  139,  166,  184,\n",
      "         205,  214,  226,  260,  305,  317,  326,  351,  380,  407,  430,  457,\n",
      "         484,  502,  566,  572,  580,  592,  597,  630,  660,  679,  702,  741,\n",
      "         753,  769,  794,  832,  845,  862,  867,  889,  912,  921,  933,  959,\n",
      "         981,  997, 1014, 1031, 1048, 1063, 1104, 1113, 1133, 1156, 1177, 1221,\n",
      "        1257, 1266, 1296, 1301])\n",
      "tensor([[-0.0155, -0.0529],\n",
      "        [-0.0816, -0.0073],\n",
      "        [-0.1060,  0.0286],\n",
      "        [-0.1155,  0.0570],\n",
      "        [-0.1071,  0.0533],\n",
      "        [-0.1901,  0.0742],\n",
      "        [-0.2091,  0.1079],\n",
      "        [-0.1405,  0.0790],\n",
      "        [-0.1595,  0.0518],\n",
      "        [-0.1693,  0.0819],\n",
      "        [-0.1373,  0.1055],\n",
      "        [-0.1387,  0.1220],\n",
      "        [-0.1353,  0.1216],\n",
      "        [-0.1345,  0.1289],\n",
      "        [-0.0898,  0.1226],\n",
      "        [-0.0872,  0.0930],\n",
      "        [-0.0960,  0.0613],\n",
      "        [-0.0657,  0.0684],\n",
      "        [-0.0915,  0.1005],\n",
      "        [-0.1115,  0.0918],\n",
      "        [-0.1300,  0.0897],\n",
      "        [-0.1049,  0.0613],\n",
      "        [-0.1345,  0.0882],\n",
      "        [-0.1332,  0.0744],\n",
      "        [-0.1252,  0.0526],\n",
      "        [-0.1350,  0.0775],\n",
      "        [-0.1441,  0.1033],\n",
      "        [-0.1242,  0.0671],\n",
      "        [-0.0871,  0.0914],\n",
      "        [-0.0830,  0.1031],\n",
      "        [-0.0637,  0.1161],\n",
      "        [-0.1056,  0.1182],\n",
      "        [-0.0877,  0.1181],\n",
      "        [-0.1276,  0.1378],\n",
      "        [-0.1493,  0.1187],\n",
      "        [-0.1228,  0.1040],\n",
      "        [-0.1238,  0.0763],\n",
      "        [-0.1199,  0.0917],\n",
      "        [-0.1248,  0.1011],\n",
      "        [-0.1332,  0.1163],\n",
      "        [-0.1262,  0.0955],\n",
      "        [-0.0849,  0.0633],\n",
      "        [-0.1124,  0.0928],\n",
      "        [-0.1136,  0.0897],\n",
      "        [-0.1435,  0.1144],\n",
      "        [-0.1487,  0.0962],\n",
      "        [-0.1440,  0.0300],\n",
      "        [-0.1336,  0.0354],\n",
      "        [-0.1656,  0.0590],\n",
      "        [-0.1348,  0.0685],\n",
      "        [-0.1276,  0.1003],\n",
      "        [-0.1697,  0.1016],\n",
      "        [-0.1620,  0.0641],\n",
      "        [-0.1591,  0.0745],\n",
      "        [-0.1363,  0.0626],\n",
      "        [-0.1371,  0.0925],\n",
      "        [-0.1395,  0.1009],\n",
      "        [-0.1230,  0.0810],\n",
      "        [-0.1285,  0.1249],\n",
      "        [-0.1502,  0.1268],\n",
      "        [-0.1724,  0.0892],\n",
      "        [-0.1756,  0.0754],\n",
      "        [-0.1660,  0.1017],\n",
      "        [-0.1253,  0.1458]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i, (txt, label, offset) in enumerate(train_dataloader):\n",
    "    model.eval()\n",
    "    print(label.shape)\n",
    "    print(label[0])\n",
    "    print(txt, label, offset)\n",
    "    print(model(txt, offset))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# lets try these hyperparameters, losses, and optimizers instead and see our results\n",
    "\n",
    "epochs = 200\n",
    "LR = 2\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1.0, gamma=0.0001)\n",
    "total_accu = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# redfine our datasets\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(dataset=test_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_accuracy, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, (texts, labels, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(texts, offsets)\n",
    "        labels = torch.as_tensor([a.type(torch.LongTensor) for a in labels], dtype=torch.int64)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        #our result is the largest number's index of the prediction\n",
    "        total_accuracy += (pred.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "\n",
    "        if i == 0:\n",
    "            print(loss)\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, i, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (texts, labels, offsets) in enumerate(dataloader):\n",
    "            pred = model(texts, offsets)\n",
    "            labels = torch.as_tensor([a.type(torch.LongTensor) for a in labels], dtype=torch.int64)\n",
    "            loss = criterion(pred, labels)\n",
    "            total_acc += (pred.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "            # print(pred)\n",
    "    return total_acc/total_count\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7379, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  1.64s | valid accuracy    0.716 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.7496, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.69s | valid accuracy    0.716 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.5783, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.74s | valid accuracy    0.716 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.5503, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.85s | valid accuracy    0.716 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.5853, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.88s | valid accuracy    0.718 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.5893, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.87s | valid accuracy    0.731 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.5624, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.91s | valid accuracy    0.757 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.4704, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  2.03s | valid accuracy    0.794 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.3787, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.90s | valid accuracy    0.833 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.3707, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  1.86s | valid accuracy    0.902 \n",
      "-----------------------------------------------------------\n",
      "tensor(0.2415, grad_fn=<NllLossBackward0>)\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time:  1.82s | valid accuracy    0.923 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(test_dataloader)\n",
    "\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)\n",
    "\n",
    "    if total_accu is not None and total_accu > 0.91:\n",
    "        # the accuracy is worse than the tf version (due to various reasons)\n",
    "        # but i dont have time\n",
    "        # so i'm removing bidirectional and just deploying a 94%\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "test out a save"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import app\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "target_path = os.path.join(app.root(), \"Models\", \"pytorch_joy_and_anger\", \"pytorch_joy_and_anger_model\")\n",
    "target_path_torchscript = os.path.join(app.root(), \"Models\", \"pytorch_joy_and_anger\", \"pytorch_joy_and_anger_model_torchscript.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "save_model(model, target_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# save as a torchscript file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1, 110,   2,  ...,  85,  18, 781]) tensor([   0,   20,   54,   64,   83,  102,  117,  165,  182,  196,  231,  241,\n",
      "         270,  292,  305,  340,  350,  369,  403,  431,  443,  458,  474,  491,\n",
      "         517,  528,  539,  546,  586,  605,  625,  640,  653,  664,  689,  702,\n",
      "         714,  744,  754,  798,  814,  838,  853,  864,  873,  900,  908,  929,\n",
      "         964,  983, 1009, 1019, 1064, 1076, 1085, 1089, 1115, 1121, 1134, 1154,\n",
      "        1183, 1200, 1216, 1232]) tensor([[ 1.9752, -2.4180],\n",
      "        [-0.7347,  0.7728],\n",
      "        [ 2.6012, -3.2474],\n",
      "        [-2.1131,  2.5473],\n",
      "        [ 2.5529, -3.1317],\n",
      "        [-1.5927,  1.9182],\n",
      "        [ 1.4666, -1.7872],\n",
      "        [ 0.6848, -0.8799],\n",
      "        [ 0.9376, -1.1961],\n",
      "        [ 1.6983, -2.1249],\n",
      "        [-2.0633,  2.5010],\n",
      "        [-0.1060,  0.1556],\n",
      "        [ 1.4698, -1.8034],\n",
      "        [ 1.7391, -2.1034],\n",
      "        [ 0.6155, -0.7503],\n",
      "        [-2.1758,  2.5714],\n",
      "        [ 0.1737, -0.2256],\n",
      "        [ 0.4921, -0.5993],\n",
      "        [ 1.1371, -1.3568],\n",
      "        [ 1.9698, -2.3928],\n",
      "        [ 2.0007, -2.4636],\n",
      "        [ 1.7796, -2.1032],\n",
      "        [ 1.9262, -2.3092],\n",
      "        [ 0.8722, -0.9976],\n",
      "        [ 1.8026, -2.1634],\n",
      "        [ 1.8048, -2.1805],\n",
      "        [ 2.5209, -3.1694],\n",
      "        [-0.5231,  0.6771],\n",
      "        [ 1.8270, -2.2419],\n",
      "        [ 0.2184, -0.2902],\n",
      "        [-0.8499,  0.9792],\n",
      "        [ 2.4565, -3.0815],\n",
      "        [-2.8431,  3.3863],\n",
      "        [ 2.0626, -2.5690],\n",
      "        [ 1.9033, -2.3211],\n",
      "        [ 1.7132, -2.0842],\n",
      "        [ 0.3676, -0.4765],\n",
      "        [-2.5051,  3.0426],\n",
      "        [ 0.7544, -0.9727],\n",
      "        [-2.0574,  2.3868],\n",
      "        [-0.9457,  1.1032],\n",
      "        [ 0.7222, -0.9410],\n",
      "        [ 1.7241, -2.1288],\n",
      "        [ 1.4968, -1.8877],\n",
      "        [ 0.3192, -0.4544],\n",
      "        [ 1.5126, -1.8807],\n",
      "        [ 0.0760, -0.1037],\n",
      "        [ 0.7069, -0.8285],\n",
      "        [ 0.4816, -0.5302],\n",
      "        [-0.6126,  0.8028],\n",
      "        [ 2.1985, -2.6248],\n",
      "        [ 0.6041, -0.7036],\n",
      "        [ 1.2344, -1.4972],\n",
      "        [ 1.0777, -1.3360],\n",
      "        [ 3.3396, -4.1783],\n",
      "        [-0.7446,  0.9783],\n",
      "        [ 2.0118, -2.4038],\n",
      "        [ 0.2799, -0.3483],\n",
      "        [ 1.6237, -1.9858],\n",
      "        [-0.9152,  1.0775],\n",
      "        [ 1.0323, -1.3047],\n",
      "        [-2.1475,  2.5634],\n",
      "        [ 1.5631, -2.0121],\n",
      "        [ 1.2189, -1.5881]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, (texts, labels, offsets) in enumerate(test_dataloader):\n",
    "    if i != 0:\n",
    "        break\n",
    "    traced_script_module = torch.jit.trace(model, (texts, offsets))\n",
    "    traced_script_module.save(target_path_torchscript)\n",
    "    pred = model(texts, offsets)\n",
    "    print(texts, offsets, pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3133)\n"
     ]
    }
   ],
   "source": [
    "pred = torch.as_tensor([[1., 0.]], dtype=torch.float32)\n",
    "label = torch.as_tensor([0], dtype=torch.int64)\n",
    "\n",
    "loss = criterion(pred, label)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1269)\n"
     ]
    }
   ],
   "source": [
    "pred = torch.as_tensor([[-1., 1.]], dtype=torch.float32)\n",
    "label = torch.as_tensor([1 ], dtype=torch.int64)\n",
    "\n",
    "loss = criterion(pred, label)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loss function makes sense and matches our argmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "b = [5,6,7,8]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 3, 4, 5, 6, 7, 8])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.as_tensor(a),torch.as_tensor(b)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}